{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gkLjqN4PC4Nm"
   },
   "source": [
    "In this notebook, you should use the equations and general recipe covered in the lecture to perform logistic regression on part of the MNIST dataset. When in doubt, looking at the slides may help your memory ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MBsS1qZTtAZE"
   },
   "outputs": [],
   "source": [
    "#load packages\n",
    "import numpy as np\n",
    "import sklearn.model_selection\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pfhsm8m6tFe_"
   },
   "outputs": [],
   "source": [
    "#make helper functions\n",
    "\n",
    "def plot_digit(X, y, idx):\n",
    "    img = X[idx].reshape(28,28)\n",
    "    plt.imshow(img, cmap='Greys',  interpolation='nearest')\n",
    "    plt.title('true label: %d' % y[idx])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "30OCX2pjwGdT"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlxtend'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#load data\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlxtend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mnist_data\n\u001b[1;32m      4\u001b[0m X, y \u001b[38;5;241m=\u001b[39m mnist_data()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#we just focus on 1's and 0's:\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mlxtend'"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "\n",
    "from mlxtend.data import mnist_data\n",
    "X, y = mnist_data()\n",
    "\n",
    "\n",
    "#we just focus on 1's and 0's:\n",
    "keep=(y==0) | (y==1)\n",
    "X=X[keep,:]\n",
    "y=y[keep]\n",
    "\n",
    "y=np.expand_dims(y,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qR1s1Q-twJ7Q"
   },
   "outputs": [],
   "source": [
    "#inspect data\n",
    "\n",
    "#(plot digit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4cg7bDdAwSsl"
   },
   "outputs": [],
   "source": [
    "# create a (binary cross entropy) loss function as discussed in the slides:\n",
    "def avrLoss(y,a):           #page59 in week1's slides     Binary cross-entropy function\n",
    "\n",
    "  #INSERT CODE\n",
    "\n",
    "  return np.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jlbHgUIjwXiT"
   },
   "outputs": [],
   "source": [
    "#test loss function:\n",
    "#(just run this cell and see what happens)\n",
    "\n",
    "\n",
    "loss=avrLoss(np.array([0,1,0,1]),np.linspace(.1,.9,4))\n",
    "assert np.all(loss==0.5543313122608056)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LdCmhY63weJO"
   },
   "outputs": [],
   "source": [
    "#create a sigmoid          page 58\n",
    "def sigmoid(z):\n",
    "  #INSERT CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_W17O55pwiIV"
   },
   "outputs": [],
   "source": [
    "#check sigmoid\n",
    "#(just run this cell and see what happens)\n",
    "\n",
    "out=sigmoid(np.array(range(-5,5)))\n",
    "assert np.all(np.around(out,8)==np.array([0.00669285, 0.01798621, 0.04742587, 0.11920292, 0.26894142, 0.5, 0.73105858, 0.88079708, 0.95257413, 0.98201379]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LhAlECUCwh8r"
   },
   "outputs": [],
   "source": [
    "#make test & train data\n",
    "\n",
    "Xtrain,Xtest,ytrain,ytest=sklearn.model_selection.train_test_split(X,y,test_size=0.3,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wK_4dd1ywox5"
   },
   "outputs": [],
   "source": [
    "#train\n",
    "\n",
    "#INITIATE WEIGHTS AND BIASES (w,b)\n",
    "w=?      #random\n",
    "b=?     #random\n",
    "\n",
    "nEpoch=?   #random\n",
    "\n",
    "accuracy=np.zeros(nEpoch)\n",
    "trainRate=#pick a number less than 1\n",
    "\n",
    "for iTrain in range(nEpoch):\n",
    "  #evaluate\n",
    "  #CALCULATE a\n",
    "\n",
    "  #calculate loss & accuracy\n",
    "  loss=?      #use the function you defined\n",
    "\n",
    "  yhat=a>.5\n",
    "  accuracy[iTrain]=np.mean(yhat==ytrain)\n",
    "\n",
    "\n",
    "  #update weights       page62      the same page with 'UPDATE W AND b'\n",
    "  wgrad=?   #a,ytrain,and xtrian.T,\n",
    "  bgrad=?\n",
    "\n",
    "#formulas are in page 62,and a is calculated from sigmoid ; y is ytrain;\n",
    "#                           and x is the data or images you loaded\n",
    "\n",
    "\n",
    "\n",
    "  assert(wgrad.shape == w.shape)\n",
    "\n",
    "  #UPDATE W AND b\n",
    " #Notes: the 'some sensible step size' mentioned in page62 is just the trainRate\n",
    "\n",
    "  if np.mod(iTrain,10)==0:\n",
    "    print(iTrain,loss,accuracy[iTrain])\n",
    "\n",
    "Y_prediction_test = sigmoid(np.matmul(Xtest,w)+b)>0.5\n",
    "Y_prediction_train = sigmoid(np.matmul(Xtrain,w)+b)>0.5\n",
    "\n",
    "print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - ytrain)) * 100))\n",
    "print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - ytest)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8JmScwp3HJkr"
   },
   "outputs": [],
   "source": [
    "#see what the network does:\n",
    "\n",
    "img = w.reshape(28,28)\n",
    "h=plt.imshow(img, cmap='Greys',  interpolation='nearest')\n",
    "plt.colorbar(h)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "executionInfo": {
     "elapsed": 679,
     "status": "error",
     "timestamp": 1693487540336,
     "user": {
      "displayName": "Kaare Mikkelsen",
      "userId": "09204221925541859962"
     },
     "user_tz": -120
    },
    "id": "FhIt3afDHN8X",
    "outputId": "d928ff88-1887-47a9-dc9f-4f71d499baa2"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6fedd0818f01>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Xtrain' is not defined"
     ]
    }
   ],
   "source": [
    "#commpare with scikit-learn:\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0).fit(Xtrain, ytrain)\n",
    "\n",
    "clf.predict(X)\n",
    "print('Train accuracy: ',clf.score(Xtrain, ytrain))\n",
    "print('Test accuracy: ',clf.score(Xtest, ytest))\n",
    "\n",
    "img = (clf.coef_).reshape(28,28)\n",
    "plt.imshow(img, cmap='Greys',  interpolation='nearest')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
